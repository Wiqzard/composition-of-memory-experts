# @package _global_

defaults:
  - override /data: minecraft_marsh 
  - override /model: video_diffusion
  - override /callbacks: default
  - override /trainer: ddp
  - override /logger: wandb
  - override /paths: default

tags: ["ddpm", "debug", "minecraft"]

seed: 42
training: False
validation: True
test: False
ckpt_path:


trainer:
  strategy: auto 
  devices: 8 # 8
  limit_val_batches: 32 #64 #32 #64 ###32
  val_check_interval: 2000 #1 #2000 #1000
  log_every_n_steps: 1
  num_sanity_val_steps: 1
  precision: 16-mixed #16-true


data:
  batch_size: 2 #2 #
  overwrite_split: #validation
  dataset_cls:
    n_frames: 70 #102 #149 #77 #127 #149 #127 #149 #127 #149 #77 #30 #90 #130 #150 #90 #110 #65 #90 #110 #150  # n_context + h(chunk_size - sliding_window)
    max_frames: 70 #10 # total frames in training
    save_dir: /data/cvg/sebastian/minecraft_marsh/dataset 

model:
  #ckpt_path: /home/ss24m050/Documents/phd_playground/logs/train/2025-05-12_11-17-34/checkpoints/last.ckpt #/home/ss24m050/Documents/phd_playground/data/ckpts/DFoT_MCRAFT.ckpt # data/ckpts/mc_25_frames.ckpt #
  #ckpt_path: /home/ss24m050/Documents/phd_playground/logs/train/2025-05-12_11-17-34/checkpoints/last.ckpt #/home/ss24m050/Documents/phd_playground/data/ckpts/DFoT_MCRAFT.ckpt # data/ckpts/mc_25_frames.ckpt #
  ckpt_path: data/ckpts/DFoT_MCRAFT.ckpt
  compile: true #_without_ddp_optimizer
  vae_pretrained_path: data/ckpts/ImageVAE_MCRAFT.ckpt
  is_latent_diffusion: True 

  # Metrics Configuration
  metrics: [mse, psnr, ssim, fid, fvd, lpips] #[fvd, is, fid, lpips, mse, psnr, ssim, vbench]
  metrics_batch_size: 4
  n_metrics_frames: null # 50
  exclude_context: true # excludes context frames from the video metrics computation such as FVD (image metrics are already excluded)

  # Checkpoint
  strict_load:  False
  reset_optimizer: False

  # Logging Configuration
  log_max_num_videos: 32 #1256 #256 #32 #256

  # General Configuration
  context_frames: 53 #75 #50 #100 #50 #100 #50 #30 #90 #25 #50 #90 #25 #50 #50 #50 #10 #120 #50  # number of total context frames
  sliding_context_len: 53 # 1   # the amount context frames within attention window
  chunk_size: 70 # limits the horizon if use_causal_mask is true
  use_causal_mask: False #True # for autoregressive prediction
  sampling_timesteps: 50

  fixed_context:
    enabled: false
    indices: null
    dropout: 0.3

  variable_context:
    enabled: false
    prob: 0.5
    dropout: 0.3

  uniform_future: true # negates future
  noise_level: random_independent #random_uniform
  scheduling_matrix: full_sequence

  # Tasks
  tasks: [prediction]

  # Adapter

  # Main Model
  diffusion_model:
    _partial_: true
    _target_: src.models.components.diffusion.continuous_diffusion_v2.ContinuousDiffusion
    model:
      _partial_: true
      _target_: src.models.components.backbones.dit.dit3d_base.DiT3D
      hidden_size: 768
      patch_size: 4
      variant: full
      pos_emb_type: rope_3d
      depth: 12
      num_heads: 12
      mlp_ratio: 4
      use_gradient_checkpointing: False
      use_fourier_noise_embedding: True
      external_cond_dropout: 0.05
      use_causal_mask: ${model.use_causal_mask}
    # ----------------- DISCRETE ----------------- #
    #    timesteps: 1000 #${model.sampling_timesteps}
    #sampling_timesteps: ${model.sampling_timesteps}
    #beta_schedule: cosine #_simple_diffusion
    ##schedule_fn_kwargs:
    ##shifted: 0.125
    #objective: pred_noise #pred_v
    #loss_weighting:
    #strategy: sigmoid #fused_min_snr #sigmoid #used_min_snr #sigmoid #sigmoid
    ##snr_clip: 5
    ##cum_snr_decay: 0.9
    #sigmoid_bias: -1
    #clip_noise: ${model.clip_noise}
    #use_causal_mask: False
    # ----------------- CONTINUOUS----------------- #
    timesteps: 1000
    use_causal_mask: ${model.use_causal_mask}
    clip_noise: ${model.clip_noise}
    objective: pred_v
    beta_schedule: cosine_simple_diffusion
    loss_weighting:
      strategy: sigmoid
      sigmoid_bias: -1
    training_schedule: cosine
    training_schedule_shift: 0.125
    schedule_fn_kwargs:
      shifted: 0.125
    sampling_timesteps: ${model.sampling_timesteps}
    precond_scale: 0.125

  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: 0.00006 #1
    weight_decay: 0.001

  lr_scheduler:
    _target_: transformers.get_scheduler
    _partial_: true
    name: constant_with_warmup
    num_warmup_steps: 1000
    num_training_steps: 500000

callbacks:
  ema:
    enabled: false
    decay: 0.9999
    validate_original_weights: false 

  early_stopping:
    monitor: "prediction/VideoMetricType.FVD"
    patience: 10000
    mode: "min"

  model_checkpoint:
    save_top_k: 4
    monitor: "prediction/VideoMetricType.FVD"
    filename: "epoch-{epoch:02d}-step-{step}-FVD-{prediction/VideoMetricType.FVD:.2f}"
    mode: "min"

logger:
  wandb:
    tags: ${tags}
    project: memory_adaptation_mc
    #id: vasew1je
